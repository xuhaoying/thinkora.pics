#!/usr/bin/env python3
"""
å¤šå¹³å°é€æ˜PNGä¸‹è½½å™¨ - æ”¯æŒUnsplashã€Pexelsã€Pixabay
"""

import os
import json
import requests
import time
import hashlib
from pathlib import Path
from datetime import datetime, timedelta
from dotenv import load_dotenv
import argparse
import sys
from abc import ABC, abstractmethod

# macOS ç‰¹å®šé…ç½®
if sys.platform == "darwin":
    os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

class PlatformDownloader(ABC):
    """æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰ä¸‹è½½å™¨æ¥å£"""
    
    @abstractmethod
    def search_photos(self, query: str, page: int = 1, per_page: int = 30):
        """æœç´¢å›¾ç‰‡"""
        pass
    
    @abstractmethod
    def download_photo(self, photo_data: dict):
        """ä¸‹è½½å•å¼ å›¾ç‰‡"""
        pass
    
    @abstractmethod
    def get_photo_url(self, photo_data: dict):
        """è·å–å›¾ç‰‡ä¸‹è½½URL"""
        pass

class UnsplashDownloader(PlatformDownloader):
    """Unsplashä¸‹è½½å™¨"""
    
    def __init__(self, access_key: str):
        self.access_key = access_key
        self.base_url = "https://api.unsplash.com"
    
    def search_photos(self, query: str, page: int = 1, per_page: int = 30):
        """æœç´¢Unsplashå›¾ç‰‡"""
        response = requests.get(
            f"{self.base_url}/search/photos",
            params={
                "query": query,
                "per_page": per_page,
                "page": page,
                "order_by": "relevant"
            },
            headers={"Authorization": f"Client-ID {self.access_key}"},
            timeout=10
        )
        
        if response.status_code != 200:
            raise Exception(f"Unsplash APIé”™è¯¯: {response.status_code}")
        
        data = response.json()
        return data.get("results", [])
    
    def get_photo_url(self, photo_data: dict):
        """è·å–Unsplashå›¾ç‰‡URL"""
        return photo_data["urls"]["regular"]
    
    def download_photo(self, photo_data: dict):
        """ä¸‹è½½Unsplashå›¾ç‰‡"""
        photo_id = photo_data["id"]
        download_url = self.get_photo_url(photo_data)
        
        # ä¸‹è½½å›¾ç‰‡
        img_response = requests.get(download_url, timeout=15)
        if img_response.status_code != 200:
            raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: HTTP {img_response.status_code}")
        
        # ä¿å­˜æ–‡ä»¶
        filename = f"raw/{photo_id}.jpg"
        with open(filename, "wb") as f:
            f.write(img_response.content)
        
        # å‘é€ä¸‹è½½ç»Ÿè®¡
        try:
            requests.get(
                photo_data["links"]["download_location"],
                headers={"Authorization": f"Client-ID {self.access_key}"},
                timeout=5
            )
        except:
            pass  # å¿½ç•¥ç»Ÿè®¡å‘é€å¤±è´¥
        
        return {
            "id": photo_id,
            "filename": filename,
            "size": len(img_response.content),
            "platform": "unsplash"
        }

class PexelsDownloader(PlatformDownloader):
    """Pexelsä¸‹è½½å™¨"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.pexels.com/v1"
    
    def search_photos(self, query: str, page: int = 1, per_page: int = 30):
        """æœç´¢Pexelså›¾ç‰‡"""
        response = requests.get(
            f"{self.base_url}/search",
            params={
                "query": query,
                "page": page,
                "per_page": per_page
            },
            headers={"Authorization": self.api_key},
            timeout=10
        )
        
        if response.status_code != 200:
            raise Exception(f"Pexels APIé”™è¯¯: {response.status_code}")
        
        data = response.json()
        return data.get("photos", [])
    
    def get_photo_url(self, photo_data: dict):
        """è·å–Pexelså›¾ç‰‡URL"""
        # é€‰æ‹©ä¸­ç­‰å¤§å°çš„å›¾ç‰‡
        return photo_data["src"]["medium"]
    
    def download_photo(self, photo_data: dict):
        """ä¸‹è½½Pexelså›¾ç‰‡"""
        photo_id = photo_data["id"]
        download_url = self.get_photo_url(photo_data)
        
        # ä¸‹è½½å›¾ç‰‡
        img_response = requests.get(download_url, timeout=15)
        if img_response.status_code != 200:
            raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: HTTP {img_response.status_code}")
        
        # ä¿å­˜æ–‡ä»¶
        filename = f"raw/pexels_{photo_id}.jpg"
        with open(filename, "wb") as f:
            f.write(img_response.content)
        
        return {
            "id": f"pexels_{photo_id}",
            "filename": filename,
            "size": len(img_response.content),
            "platform": "pexels"
        }

class PixabayDownloader(PlatformDownloader):
    """Pixabayä¸‹è½½å™¨"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://pixabay.com/api"
    
    def search_photos(self, query: str, page: int = 1, per_page: int = 30):
        """æœç´¢Pixabayå›¾ç‰‡"""
        response = requests.get(
            self.base_url,
            params={
                "key": self.api_key,
                "q": query,
                "page": page,
                "per_page": per_page,
                "image_type": "photo",
                "safesearch": "true"
            },
            timeout=10
        )
        
        if response.status_code != 200:
            raise Exception(f"Pixabay APIé”™è¯¯: {response.status_code}")
        
        data = response.json()
        return data.get("hits", [])
    
    def get_photo_url(self, photo_data: dict):
        """è·å–Pixabayå›¾ç‰‡URL"""
        # é€‰æ‹©ä¸­ç­‰å¤§å°çš„å›¾ç‰‡
        return photo_data["webformatURL"]
    
    def download_photo(self, photo_data: dict):
        """ä¸‹è½½Pixabayå›¾ç‰‡"""
        photo_id = photo_data["id"]
        download_url = self.get_photo_url(photo_data)
        
        # ä¸‹è½½å›¾ç‰‡
        img_response = requests.get(download_url, timeout=15)
        if img_response.status_code != 200:
            raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: HTTP {img_response.status_code}")
        
        # ä¿å­˜æ–‡ä»¶
        filename = f"raw/pixabay_{photo_id}.jpg"
        with open(filename, "wb") as f:
            f.write(img_response.content)
        
        return {
            "id": f"pixabay_{photo_id}",
            "filename": filename,
            "size": len(img_response.content),
            "platform": "pixabay"
        }

class MultiPlatformDownloader:
    """å¤šå¹³å°ä¸‹è½½å™¨ä¸»ç±»"""
    
    def __init__(self):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # åˆå§‹åŒ–å„å¹³å°ä¸‹è½½å™¨
        self.downloaders = {}
        
        # Unsplash
        unsplash_key = os.getenv("UNSPLASH_ACCESS_KEY")
        if unsplash_key:
            self.downloaders["unsplash"] = UnsplashDownloader(unsplash_key)
            print("âœ… Unsplashä¸‹è½½å™¨å·²åˆå§‹åŒ–")
        
        # Pexels
        pexels_key = os.getenv("PEXELS_API_KEY")
        if pexels_key:
            self.downloaders["pexels"] = PexelsDownloader(pexels_key)
            print("âœ… Pexelsä¸‹è½½å™¨å·²åˆå§‹åŒ–")
        
        # Pixabay
        pixabay_key = os.getenv("PIXABAY_API_KEY")
        if pixabay_key:
            self.downloaders["pixabay"] = PixabayDownloader(pixabay_key)
            print("âœ… Pixabayä¸‹è½½å™¨å·²åˆå§‹åŒ–")
        
        if not self.downloaders:
            print("âŒ é”™è¯¯ï¼šè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®è‡³å°‘ä¸€ä¸ªå¹³å°çš„APIå¯†é’¥")
            print("ğŸ’¡ æ”¯æŒçš„å¹³å°ï¼šUNSPLASH_ACCESS_KEY, PEXELS_API_KEY, PIXABAY_API_KEY")
            sys.exit(1)
        
        # æ–‡ä»¶è·¯å¾„
        self.state_file = "download_state.json"
        self.downloaded_ids_file = "downloaded_ids.json"
        self.metadata_file = "metadata.json"
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        Path("raw").mkdir(exist_ok=True)
        Path("png").mkdir(exist_ok=True)
        Path("logs").mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.load_state()
        self.load_downloaded_ids()
        
        # æŸ¥è¯¢é…ç½®
        self.queries = [
            "laptop computer minimal",
            "smartphone mobile device", 
            "coffee cup workspace",
            "office supplies desk",
            "plant succulent office",
            "book notebook reading",
            "camera photography",
            "headphones audio tech",
            "modern furniture",
            "kitchen appliances",
            "fashion accessories",
            "sports equipment",
            "musical instruments",
            "art supplies",
            "garden tools"
        ]
        
        print(f"ğŸš€ å¤šå¹³å°ä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“‚ å·¥ä½œç›®å½•: {os.getcwd()}")
        print(f"ğŸ”‘ å·²é…ç½®å¹³å°: {list(self.downloaders.keys())}")
    
    def load_state(self):
        """åŠ è½½ä¸‹è½½çŠ¶æ€"""
        if Path(self.state_file).exists():
            with open(self.state_file, 'r') as f:
                self.state = json.load(f)
        else:
            self.state = {
                "last_run": None,
                "total_downloaded": 0,
                "requests_this_hour": 0,
                "hour_start": None,
                "current_query_index": 0,
                "current_platform_index": 0
            }
    
    def save_state(self):
        """ä¿å­˜çŠ¶æ€"""
        self.state["last_run"] = datetime.now().isoformat()
        with open(self.state_file, 'w') as f:
            json.dump(self.state, f, indent=2)
    
    def load_downloaded_ids(self):
        """åŠ è½½å·²ä¸‹è½½ID"""
        if Path(self.downloaded_ids_file).exists():
            with open(self.downloaded_ids_file, 'r') as f:
                self.downloaded_ids = set(json.load(f))
        else:
            self.downloaded_ids = set()
        
        print(f"ğŸ“‹ å·²è®°å½• {len(self.downloaded_ids)} ä¸ªå·²ä¸‹è½½å›¾ç‰‡")
    
    def save_downloaded_ids(self):
        """ä¿å­˜å·²ä¸‹è½½ID"""
        with open(self.downloaded_ids_file, 'w') as f:
            json.dump(list(self.downloaded_ids), f)
    
    def check_api_limit(self):
        """æ£€æŸ¥APIé™åˆ¶"""
        now = datetime.now()
        
        if self.state["hour_start"]:
            hour_start = datetime.fromisoformat(self.state["hour_start"])
            if now - hour_start >= timedelta(hours=1):
                # é‡ç½®è®¡æ•°å™¨
                self.state["requests_this_hour"] = 0
                self.state["hour_start"] = now.isoformat()
        else:
            self.state["hour_start"] = now.isoformat()
        
        # æ¯å°æ—¶é™åˆ¶100ä¸ªè¯·æ±‚ï¼ˆä¿å®ˆä¼°è®¡ï¼‰
        return self.state["requests_this_hour"] < 90
    
    def download_batch(self, batch_size=15):
        """ä¸‹è½½ä¸€æ‰¹å›¾ç‰‡"""
        if not self.check_api_limit():
            remaining_time = 3600 - (datetime.now() - datetime.fromisoformat(self.state["hour_start"])).total_seconds()
            print(f"â° APIé™åˆ¶å·²è¾¾ä¸Šé™ï¼Œéœ€ç­‰å¾… {remaining_time/60:.1f} åˆ†é’Ÿ")
            return 0
        
        # é€‰æ‹©å¹³å°å’ŒæŸ¥è¯¢
        platforms = list(self.downloaders.keys())
        platform = platforms[self.state["current_platform_index"]]
        self.state["current_platform_index"] = (self.state["current_platform_index"] + 1) % len(platforms)
        
        query = self.queries[self.state["current_query_index"]]
        self.state["current_query_index"] = (self.state["current_query_index"] + 1) % len(self.queries)
        
        print(f"\nğŸ” å¼€å§‹ä¸‹è½½: {platform.upper()} - '{query}' (ç›®æ ‡: {batch_size} å¼ )")
        
        downloaded = 0
        page = 1
        
        while downloaded < batch_size and self.check_api_limit():
            try:
                # æœç´¢å›¾ç‰‡
                print(f"ğŸ“¡ æœç´¢ç¬¬ {page} é¡µ...")
                photos = self.downloaders[platform].search_photos(query, page, 30)
                self.state["requests_this_hour"] += 1
                
                if not photos:
                    print("ğŸ“„ æ²¡æœ‰æ›´å¤šç»“æœ")
                    break
                
                print(f"âœ… æ‰¾åˆ° {len(photos)} å¼ å›¾ç‰‡")
                
                for i, photo in enumerate(photos):
                    if downloaded >= batch_size:
                        break
                    
                    try:
                        # æ£€æŸ¥é‡å¤
                        photo_id = photo.get("id", f"{platform}_{i}")
                        if platform != "unsplash":
                            photo_id = f"{platform}_{photo_id}"
                        
                        if photo_id in self.downloaded_ids:
                            print(f"â­ï¸ è·³è¿‡é‡å¤å›¾ç‰‡: {photo_id}")
                            continue
                        
                        # è´¨é‡æ£€æŸ¥
                        if platform == "unsplash":
                            if photo["width"] < 1000 or photo["height"] < 1000:
                                print(f"âš ï¸ è·³è¿‡ä½è´¨é‡å›¾ç‰‡: {photo_id}")
                                continue
                        
                        # ä¸‹è½½å›¾ç‰‡
                        result = self.downloaders[platform].download_photo(photo)
                        downloaded += 1
                        self.downloaded_ids.add(result["id"])
                        
                        # ä¿å­˜å…ƒæ•°æ®
                        self.save_image_metadata(photo, platform, result)
                        
                        print(f"âœ… å·²ä¸‹è½½: {result['id']} ({downloaded}/{batch_size})")
                        
                        if not self.check_api_limit():
                            print("âš ï¸ è¾¾åˆ°APIé™åˆ¶")
                            break
                            
                    except Exception as e:
                        print(f"âŒ å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
                        continue
                
                page += 1
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ä¸‹è½½å‡ºé”™: {e}")
                break
        
        self.state["total_downloaded"] += downloaded
        self.save_state()
        self.save_downloaded_ids()
        
        print(f"\nğŸ‰ æœ¬æ‰¹æ¬¡å®Œæˆ: {downloaded} å¼ ")
        print(f"ğŸ“Š æ€»è®¡ä¸‹è½½: {self.state['total_downloaded']} å¼ ")
        print(f"ğŸ”„ APIä½¿ç”¨: {self.state['requests_this_hour']}/90")
        
        return downloaded
    
    def save_image_metadata(self, photo: dict, platform: str, result: dict):
        """ä¿å­˜å›¾ç‰‡å…ƒæ•°æ®"""
        try:
            # åŠ è½½ç°æœ‰å…ƒæ•°æ®
            metadata = {}
            if Path(self.metadata_file).exists():
                with open(self.metadata_file, 'r') as f:
                    metadata = json.load(f)
                if isinstance(metadata, list):
                    print("âš ï¸ metadata.json is a list, converting to dict.")
                    metadata = {}
            
            # æ ¹æ®å¹³å°æå–ä¿¡æ¯
            if platform == "unsplash":
                title = photo.get("description") or photo.get("alt_description") or f"Unsplash Image {photo['id']}"
                author = photo["user"]["name"]
                author_url = photo["user"]["links"]["html"]
                width = photo["width"]
                height = photo["height"]
                original_url = photo["links"]["html"]
            elif platform == "pexels":
                title = photo.get("alt", f"Pexels Image {photo['id']}")
                author = photo["photographer"]
                author_url = photo["photographer_url"]
                width = photo["width"]
                height = photo["height"]
                original_url = photo["url"]
            elif platform == "pixabay":
                title = photo.get("tags", f"Pixabay Image {photo['id']}")
                author = photo["user"]
                author_url = f"https://pixabay.com/users/{photo['user_id']}/"
                width = photo["imageWidth"]
                height = photo["imageHeight"]
                original_url = photo["pageURL"]
            
            # æ·»åŠ æ–°æ•°æ®
            metadata[result["id"]] = {
                "id": result["id"],
                "title": title,
                "author": author,
                "author_url": author_url,
                "description": f"High-quality transparent background PNG image from {platform.title()}",
                "width": width,
                "height": height,
                "platform": platform,
                "original_url": original_url,
                "downloaded_at": datetime.now().isoformat(),
                "raw_path": result["filename"],
                "file_size": f"{result['size'] / 1024 / 1024:.1f}MB",
                "tags": [
                    "transparent",
                    "png",
                    "design",
                    "isolated",
                    "cutout",
                    platform
                ],
                "category": "general",
                "quality_score": 95,
                "transparent_ratio": 0.3,  # é»˜è®¤å€¼ï¼Œåç»­å¤„ç†æ—¶æ›´æ–°
                "copyright": {
                    "platform": platform,
                    "license": f"{platform}_license",
                    "attribution_required": False,
                    "commercial_allowed": True,
                    "modification_allowed": True
                }
            }
            
            # ä¿å­˜å…ƒæ•°æ®
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
    
    def process_images(self):
        """å¤„ç†å›¾ç‰‡ï¼ˆå»èƒŒæ™¯ï¼‰"""
        try:
            from rembg import remove, new_session
            from PIL import Image
        except ImportError:
            print("âŒ ç¼ºå°‘ä¾èµ–ï¼Œè¯·è¿è¡Œï¼špip install rembg pillow")
            return
        
        print("\nğŸ¨ å¼€å§‹å»èƒŒæ™¯å¤„ç†...")
        
        # è·å–éœ€è¦å¤„ç†çš„å›¾ç‰‡
        raw_images = list(Path("raw").glob("*.jpg"))
        processed_images = set(p.stem for p in Path("png").glob("*.png"))
        
        to_process = [img for img in raw_images if img.stem not in processed_images]
        
        if not to_process:
            print("âœ… æ‰€æœ‰å›¾ç‰‡å·²å¤„ç†å®Œæˆ")
            return
        
        print(f"ğŸ“¸ éœ€è¦å¤„ç† {len(to_process)} å¼ å›¾ç‰‡")
        
        # åˆ›å»ºå»èƒŒæ™¯ä¼šè¯
        session = new_session("u2net")
        
        for i, img_path in enumerate(to_process):
            try:
                print(f"ğŸ–¼ï¸ å¤„ç†ä¸­: {img_path.name} ({i+1}/{len(to_process)})")
                
                with Image.open(img_path) as img:
                    # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œå…ˆç¼©æ”¾
                    if max(img.size) > 2048:
                        ratio = 2048 / max(img.size)
                        new_size = tuple(int(dim * ratio) for dim in img.size)
                        img = img.resize(new_size, Image.Resampling.LANCZOS)
                    
                    # å»èƒŒæ™¯
                    output = remove(img, session=session)
                    
                    # ä¿å­˜PNG
                    png_path = f"png/{img_path.stem}.png"
                    output.save(png_path, "PNG", optimize=True)
                    
                    print(f"âœ… å®Œæˆ: {png_path}")
                
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {img_path.name}: {e}")
        
        print("ğŸ‰ å›¾ç‰‡å¤„ç†å®Œæˆï¼")

def main():
    parser = argparse.ArgumentParser(description="å¤šå¹³å°é€æ˜PNGä¸‹è½½å™¨")
    parser.add_argument("--download", type=int, default=0, help="ä¸‹è½½å›¾ç‰‡æ•°é‡")
    parser.add_argument("--process", action="store_true", help="å¤„ç†å›¾ç‰‡ï¼ˆå»èƒŒæ™¯ï¼‰")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºçŠ¶æ€")
    parser.add_argument("--platform", choices=["unsplash", "pexels", "pixabay", "all"], default="all", help="æŒ‡å®šå¹³å°")
    args = parser.parse_args()
    
    downloader = MultiPlatformDownloader()
    
    if args.status:
        print(f"\nğŸ“Š å½“å‰çŠ¶æ€:")
        print(f"å·²ä¸‹è½½: {downloader.state['total_downloaded']} å¼ ")
        print(f"æœ¬å°æ—¶è¯·æ±‚: {downloader.state['requests_this_hour']}/90")
        print(f"åŸå›¾æ–‡ä»¶: {len(list(Path('raw').glob('*.jpg')))}")
        print(f"PNGæ–‡ä»¶: {len(list(Path('png').glob('*.png')))}")
        print(f"å¯ç”¨å¹³å°: {list(downloader.downloaders.keys())}")
    
    elif args.download > 0:
        downloader.download_batch(args.download)
    
    elif args.process:
        downloader.process_images()
    
    else:
        print("\nğŸš€ å¤šå¹³å°é€æ˜PNGä¸‹è½½å™¨")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python multi_platform_downloader.py --download 20    # ä¸‹è½½20å¼ å›¾ç‰‡")
        print("  python multi_platform_downloader.py --process        # å¤„ç†å›¾ç‰‡å»èƒŒæ™¯")
        print("  python multi_platform_downloader.py --status         # æŸ¥çœ‹çŠ¶æ€")
        print("  python multi_platform_downloader.py --platform pexels --download 10  # æŒ‡å®šå¹³å°")

if __name__ == "__main__":
    main() 