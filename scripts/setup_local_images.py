#!/usr/bin/env python3
"""
è®¾ç½®æœ¬åœ°å›¾ç‰‡ - å°†å›¾ç‰‡å¤åˆ¶åˆ°publicç›®å½•ï¼Œä½¿é¡¹ç›®å¯ä»¥ç«‹å³è¿è¡Œ
"""

import os
import shutil
import sqlite3
import json
from datetime import datetime

def setup_local_images():
    """å°†å›¾ç‰‡å¤åˆ¶åˆ°public/imagesç›®å½•"""
    print("ğŸš€ è®¾ç½®æœ¬åœ°å›¾ç‰‡...")
    
    # åˆ›å»ºpublic/imagesç›®å½•
    public_images_dir = 'public/images'
    os.makedirs(public_images_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰éœ€è¦çš„å›¾ç‰‡
    conn = sqlite3.connect('thinkora.db')
    cursor = conn.cursor()
    cursor.execute("SELECT id FROM images WHERE tags != '[]'")
    image_ids = [row[0] for row in cursor.fetchall()]
    conn.close()
    
    print(f"ğŸ“¸ éœ€è¦å¤„ç† {len(image_ids)} å¼ å›¾ç‰‡")
    
    copied_count = 0
    for image_id in image_ids:
        # æŸ¥æ‰¾æºæ–‡ä»¶
        source_paths = [
            f'raw/pixabay/{image_id}.jpg',
            f'raw/pixabay/{image_id}.jpeg',
            f'raw/unsplash/{image_id}.jpg',
            f'raw/pexels/{image_id}.jpg',
        ]
        
        source_file = None
        for path in source_paths:
            if os.path.exists(path):
                source_file = path
                break
        
        if source_file:
            # å¤åˆ¶åˆ°public/images
            dest_file = os.path.join(public_images_dir, f'{image_id}.jpg')
            shutil.copy2(source_file, dest_file)
            copied_count += 1
            print(f"âœ… å¤åˆ¶: {image_id}.jpg")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°: {image_id}")
    
    print(f"\nâœ… æˆåŠŸå¤åˆ¶ {copied_count} å¼ å›¾ç‰‡åˆ° {public_images_dir}")
    
    # æ›´æ–°æ•°æ®åº“URLä¸ºç›¸å¯¹è·¯å¾„
    print("\nğŸ“ æ›´æ–°æ•°æ®åº“URL...")
    conn = sqlite3.connect('thinkora.db')
    cursor = conn.cursor()
    
    cursor.execute("""
        UPDATE images 
        SET url_thumbnail = '/images/' || id || '.jpg',
            url_regular = '/images/' || id || '.jpg',
            url_download = '/images/' || id || '.jpg'
        WHERE tags != '[]'
    """)
    
    conn.commit()
    conn.close()
    print("âœ… æ•°æ®åº“URLå·²æ›´æ–°")
    
    # æ›´æ–°metadata.json
    print("\nğŸ“ æ›´æ–°metadata.json...")
    with open('metadata.json', 'r') as f:
        metadata = json.load(f)
    
    metadata['lastUpdated'] = datetime.now().isoformat()
    for image in metadata['images']:
        image_id = image['id']
        local_url = f'/images/{image_id}.jpg'
        image['urls'] = {
            'thumbnail': local_url,
            'regular': local_url,
            'download': local_url
        }
    
    with open('metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print("âœ… metadata.jsonå·²æ›´æ–°")
    
    # åˆ›å»ºä¸€ä¸ªè¯´æ˜æ–‡ä»¶
    with open('public/images/README.md', 'w') as f:
        f.write(f"""# å›¾ç‰‡ç›®å½•

æ­¤ç›®å½•åŒ…å« {copied_count} å¼ å›¾ç‰‡ï¼Œç”¨äºæœ¬åœ°å¼€å‘ã€‚

## æ³¨æ„äº‹é¡¹
- è¿™äº›å›¾ç‰‡æ˜¯ä» raw/pixabay å¤åˆ¶è¿‡æ¥çš„
- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™äº›å›¾ç‰‡åº”è¯¥ä»R2åŠ è½½
- è¿è¡Œ `python3 scripts/restore_r2_urls.py` å¯ä»¥æ¢å¤R2çš„URL
""")
    
    print("\nğŸ‰ è®¾ç½®å®Œæˆï¼")
    print("   ç°åœ¨å¯ä»¥è¿è¡Œ npm run dev æŸ¥çœ‹ç½‘ç«™")
    print("   æ‰€æœ‰å›¾ç‰‡éƒ½ä¼šä» /public/images åŠ è½½")

def main():
    setup_local_images()

if __name__ == '__main__':
    main()