#!/usr/bin/env python3
"""
ä¸Šä¼ PNGå›¾ç‰‡åˆ°Cloudflare R2å­˜å‚¨
"""

import os
import logging
import boto3
import sqlite3
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from botocore.config import Config
import time
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class R2Uploader:
    def __init__(self):
        """åˆå§‹åŒ–R2å®¢æˆ·ç«¯"""
        # ä»ç¯å¢ƒå˜é‡è·å–è®¤è¯ä¿¡æ¯
        self.access_key = os.getenv('R2_ACCESS_KEY_ID') or os.getenv('R2_ACCESS_KEY')
        self.secret_key = os.getenv('R2_SECRET_ACCESS_KEY') or os.getenv('R2_SECRET_KEY')
        self.account_id = os.getenv('R2_ACCOUNT_ID')
        self.bucket_name = os.getenv('R2_BUCKET') or os.getenv('R2_BUCKET_NAME') or "thinkora-pics"
        self.endpoint_url = os.getenv('R2_ENDPOINT')
        self.public_url = os.getenv('R2_PUBLIC_URL')
        
        # å¦‚æœæ²¡æœ‰endpointï¼Œä½¿ç”¨account_idæ„å»º
        if not self.endpoint_url and self.account_id:
            self.endpoint_url = f"https://{self.account_id}.r2.cloudflarestorage.com"
        
        if not all([self.access_key, self.secret_key, self.endpoint_url]):
            logger.error("âŒ è¯·è®¾ç½®R2ç¯å¢ƒå˜é‡:")
            logger.error("   R2_ACCESS_KEY_ID æˆ– R2_ACCESS_KEY")
            logger.error("   R2_SECRET_ACCESS_KEY æˆ– R2_SECRET_KEY")
            logger.error("   R2_ENDPOINT æˆ– R2_ACCOUNT_ID")
            logger.error(f"\nå½“å‰ç¯å¢ƒå˜é‡:")
            logger.error(f"   Access Key: {'å·²è®¾ç½®' if self.access_key else 'æœªè®¾ç½®'}")
            logger.error(f"   Secret Key: {'å·²è®¾ç½®' if self.secret_key else 'æœªè®¾ç½®'}")
            logger.error(f"   Endpoint: {self.endpoint_url or 'æœªè®¾ç½®'}")
            logger.error(f"   Bucket: {self.bucket_name}")
            raise ValueError("Missing R2 credentials")
        
        # åˆ›å»ºS3å®¢æˆ·ç«¯ï¼ˆR2å…¼å®¹S3 APIï¼‰
        self.s3_client = boto3.client(
            's3',
            endpoint_url=self.endpoint_url,
            aws_access_key_id=self.access_key,
            aws_secret_access_key=self.secret_key,
            config=Config(
                region_name='auto',
                retries={'max_attempts': 3}
            )
        )
        
        logger.info(f"âœ… R2å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"   Endpoint: {self.endpoint_url}")
        logger.info(f"   Bucket: {self.bucket_name}")
    
    def test_connection(self):
        """æµ‹è¯•R2è¿æ¥"""
        try:
            # å°è¯•åˆ—å‡ºbucket
            response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                MaxKeys=1
            )
            logger.info("âœ… R2è¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ R2è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def upload_file(self, local_path: str, r2_key: str) -> bool:
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ°R2"""
        try:
            # è®¾ç½®PNGçš„æ­£ç¡®Content-Type
            extra_args = {
                'ContentType': 'image/png',
                'CacheControl': 'public, max-age=31536000'  # 1å¹´ç¼“å­˜
            }
            
            self.s3_client.upload_file(
                local_path,
                self.bucket_name,
                r2_key,
                ExtraArgs=extra_args
            )
            
            return True
            
        except Exception as e:
            logger.error(f"ä¸Šä¼ å¤±è´¥ {r2_key}: {e}")
            return False
    
    def get_uploaded_files(self):
        """è·å–å·²ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨"""
        try:
            uploaded = set()
            paginator = self.s3_client.get_paginator('list_objects_v2')
            
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix='images/'):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        uploaded.add(obj['Key'])
            
            return uploaded
            
        except Exception as e:
            logger.error(f"è·å–å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return set()
    
    def upload_images_batch(self, images_dir='public/images_png', max_workers=5):
        """æ‰¹é‡ä¸Šä¼ å›¾ç‰‡"""
        logger.info("ğŸš€ å¼€å§‹æ‰¹é‡ä¸Šä¼ PNGå›¾ç‰‡åˆ°R2")
        
        # æ£€æŸ¥è¿æ¥
        if not self.test_connection():
            return
        
        # è·å–æ‰€æœ‰PNGæ–‡ä»¶
        png_files = list(Path(images_dir).glob('*.png'))
        total_files = len(png_files)
        
        if total_files == 0:
            logger.error(f"âŒ åœ¨ {images_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°PNGæ–‡ä»¶")
            return
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {total_files} å¼ PNGå›¾ç‰‡éœ€è¦ä¸Šä¼ ")
        
        # è·å–å·²ä¸Šä¼ çš„æ–‡ä»¶
        logger.info("ğŸ“‹ æ£€æŸ¥å·²ä¸Šä¼ çš„æ–‡ä»¶...")
        uploaded_files = self.get_uploaded_files()
        logger.info(f"å·²ä¸Šä¼ æ–‡ä»¶æ•°: {len(uploaded_files)}")
        
        # å‡†å¤‡ä¸Šä¼ ä»»åŠ¡
        upload_tasks = []
        for png_file in png_files:
            r2_key = f"images/{png_file.name}"
            if r2_key not in uploaded_files:
                upload_tasks.append((str(png_file), r2_key))
        
        logger.info(f"éœ€è¦ä¸Šä¼ : {len(upload_tasks)} å¼ å›¾ç‰‡")
        
        if len(upload_tasks) == 0:
            logger.info("âœ… æ‰€æœ‰å›¾ç‰‡éƒ½å·²ä¸Šä¼ ï¼")
            return
        
        # å¼€å§‹ä¸Šä¼ 
        start_time = datetime.now()
        success_count = 0
        fail_count = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_task = {
                executor.submit(self.upload_file, local_path, r2_key): (local_path, r2_key)
                for local_path, r2_key in upload_tasks
            }
            
            # å¤„ç†ç»“æœ
            for i, future in enumerate(as_completed(future_to_task), 1):
                local_path, r2_key = future_to_task[future]
                
                try:
                    result = future.result()
                    if result:
                        success_count += 1
                        logger.debug(f"âœ… ä¸Šä¼ æˆåŠŸ: {r2_key}")
                    else:
                        fail_count += 1
                except Exception as e:
                    fail_count += 1
                    logger.error(f"âŒ ä¸Šä¼ å¼‚å¸¸ {r2_key}: {e}")
                
                # æ¯100ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if i % 100 == 0:
                    progress = i / len(upload_tasks) * 100
                    logger.info(f"è¿›åº¦: {i}/{len(upload_tasks)} ({progress:.1f}%) - æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")
        
        # ä¸Šä¼ å®ŒæˆæŠ¥å‘Š
        elapsed = datetime.now() - start_time
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š R2ä¸Šä¼ å®ŒæˆæŠ¥å‘Š:")
        logger.info(f"  æ€»æ–‡ä»¶æ•°: {len(upload_tasks)}")
        logger.info(f"  æˆåŠŸä¸Šä¼ : {success_count}")
        logger.info(f"  ä¸Šä¼ å¤±è´¥: {fail_count}")
        logger.info(f"  æ€»è€—æ—¶: {elapsed}")
        logger.info(f"  å¹³å‡é€Ÿåº¦: {success_count / elapsed.total_seconds():.2f} æ–‡ä»¶/ç§’")
        logger.info(f"{'='*60}")
        
        if success_count > 0:
            logger.info("\nâœ… ä¸Šä¼ å®Œæˆï¼")
            logger.info(f"ğŸŒ å›¾ç‰‡å¯é€šè¿‡ä»¥ä¸‹URLè®¿é—®:")
            logger.info(f"   https://r2.thinkora.pics/images/filename.png")
            logger.info(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            logger.info(f"   1. é…ç½®R2å­˜å‚¨æ¡¶çš„å…¬å¼€è®¿é—®")
            logger.info(f"   2. è®¾ç½®è‡ªå®šä¹‰åŸŸåï¼ˆå¯é€‰ï¼‰")
            logger.info(f"   3. è¿è¡Œ: python3 scripts/restore_r2_urls.py")

def update_database_r2_urls(base_url="https://r2.thinkora.pics"):
    """æ›´æ–°æ•°æ®åº“ä¸­çš„å›¾ç‰‡URLä¸ºR2åœ°å€"""
    logger.info("ğŸ“ æ›´æ–°æ•°æ®åº“ä¸­çš„å›¾ç‰‡URLä¸ºR2åœ°å€...")
    
    conn = sqlite3.connect('images.db')
    cursor = conn.cursor()
    
    # æ›´æ–°æ‰€æœ‰URLä¸ºR2åœ°å€
    cursor.execute("""
        UPDATE images 
        SET url_thumbnail = ? || '/images/' || id || '.png',
            url_regular = ? || '/images/' || id || '.png'
        WHERE url_thumbnail LIKE '%/images/%'
    """, (base_url, base_url))
    
    updated = cursor.rowcount
    conn.commit()
    conn.close()
    
    logger.info(f"âœ… æ›´æ–°äº† {updated} æ¡æ•°æ®åº“è®°å½•")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸Šä¼ PNGå›¾ç‰‡åˆ°Cloudflare R2')
    parser.add_argument('--images-dir', default='public/images_png', help='PNGå›¾ç‰‡ç›®å½•')
    parser.add_argument('--workers', type=int, default=5, help='å¹¶å‘ä¸Šä¼ æ•°')
    parser.add_argument('--test', action='store_true', help='åªæµ‹è¯•è¿æ¥')
    parser.add_argument('--update-db', action='store_true', help='æ›´æ–°æ•°æ®åº“URLä¸ºR2åœ°å€')
    
    args = parser.parse_args()
    
    if args.update_db:
        update_database_r2_urls()
        return
    
    try:
        uploader = R2Uploader()
        
        if args.test:
            uploader.test_connection()
        else:
            uploader.upload_images_batch(args.images_dir, args.workers)
            
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main())