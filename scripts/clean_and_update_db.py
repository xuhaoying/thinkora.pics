#!/usr/bin/env python3
"""
æ¸…ç†æ— æ ‡ç­¾çš„å›¾ç‰‡å¹¶æ›´æ–°æ•°æ®åº“
"""

import os
import json
import sqlite3
from datetime import datetime
import shutil
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def analyze_current_data():
    """åˆ†æå½“å‰æ•°æ®åº“ä¸­çš„å›¾ç‰‡æ•°æ®"""
    conn = sqlite3.connect('thinkora.db')
    cursor = conn.cursor()
    
    # ç»Ÿè®¡æ ‡ç­¾æƒ…å†µ
    cursor.execute("""
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN tags = '[]' THEN 1 ELSE 0 END) as no_tags,
            SUM(CASE WHEN tags != '[]' THEN 1 ELSE 0 END) as with_tags
        FROM images
    """)
    
    total, no_tags, with_tags = cursor.fetchone()
    
    logger.info(f"ğŸ“Š å½“å‰æ•°æ®åº“ç»Ÿè®¡:")
    logger.info(f"  æ€»å›¾ç‰‡æ•°: {total}")
    logger.info(f"  æ— æ ‡ç­¾å›¾ç‰‡: {no_tags}")
    logger.info(f"  æœ‰æ ‡ç­¾å›¾ç‰‡: {with_tags}")
    
    # è·å–æ— æ ‡ç­¾å›¾ç‰‡åˆ—è¡¨
    cursor.execute("SELECT id, title FROM images WHERE tags = '[]'")
    no_tag_images = cursor.fetchall()
    
    conn.close()
    return no_tag_images, total, no_tags, with_tags

def backup_database():
    """å¤‡ä»½æ•°æ®åº“"""
    backup_name = f"thinkora_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
    shutil.copy2('thinkora.db', backup_name)
    logger.info(f"âœ… æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_name}")
    return backup_name

def import_new_images_to_db():
    """å°†æ–°ä¸‹è½½çš„å¸¦æ ‡ç­¾å›¾ç‰‡å¯¼å…¥æ•°æ®åº“"""
    conn = sqlite3.connect('thinkora.db')
    cursor = conn.cursor()
    
    imported_count = 0
    platforms = ['unsplash', 'pixabay']
    
    for platform in platforms:
        raw_dir = f'raw/{platform}'
        if not os.path.exists(raw_dir):
            continue
            
        # æŸ¥æ‰¾æ‰€æœ‰metadataæ–‡ä»¶
        for filename in os.listdir(raw_dir):
            if filename.endswith('_metadata.json'):
                metadata_path = os.path.join(raw_dir, filename)
                
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾
                    tags = data.get('tags', [])
                    if len(tags) > 0:
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        image_id = f"{platform}_{data['id']}"
                        cursor.execute("SELECT id FROM images WHERE id = ?", (image_id,))
                        
                        if not cursor.fetchone():
                            # å‡†å¤‡æ•°æ®
                            cursor.execute("""
                                INSERT INTO images (
                                    id, title, description, author_name, author_url,
                                    width, height, aspect_ratio, url_thumbnail, url_regular,
                                    url_download, tags, category, quality_score, file_size,
                                    transparent_ratio, created_at, unsplash_id, unsplash_url,
                                    unsplash_download_location
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, (
                                image_id,
                                f"{', '.join(tags[:3])} - {platform.capitalize()} Image",
                                data.get('description', ''),
                                data.get('author', 'Unknown'),
                                data.get('author_url', '#'),
                                data.get('width', 0),
                                data.get('height', 0),
                                f"{data.get('width', 1)}:{data.get('height', 1)}",
                                data.get('url', ''),
                                data.get('url', ''),
                                data.get('download_url', ''),
                                json.dumps(tags, ensure_ascii=False),
                                'photography',
                                data.get('quality_score', 0),
                                'Unknown',
                                0.0,
                                datetime.now().isoformat(),
                                data.get('id') if platform == 'unsplash' else None,
                                data.get('author_url') if platform == 'unsplash' else None,
                                data.get('download_location') if platform == 'unsplash' else None
                            ))
                            imported_count += 1
                            logger.info(f"âœ… å¯¼å…¥: {image_id} - {len(tags)} ä¸ªæ ‡ç­¾")
                        
                except Exception as e:
                    logger.error(f"å¯¼å…¥å¤±è´¥ {metadata_path}: {e}")
    
    conn.commit()
    conn.close()
    
    logger.info(f"\nğŸ“¥ æˆåŠŸå¯¼å…¥ {imported_count} å¼ æ–°å›¾ç‰‡")
    return imported_count

def remove_no_tag_images(no_tag_images):
    """ä»æ•°æ®åº“ä¸­åˆ é™¤æ— æ ‡ç­¾å›¾ç‰‡"""
    if not no_tag_images:
        logger.info("æ²¡æœ‰éœ€è¦åˆ é™¤çš„æ— æ ‡ç­¾å›¾ç‰‡")
        return 0
    
    conn = sqlite3.connect('thinkora.db')
    cursor = conn.cursor()
    
    # åˆ›å»ºä¸€ä¸ªè¡¨æ¥è®°å½•è¢«åˆ é™¤çš„å›¾ç‰‡
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS deleted_images (
            id TEXT PRIMARY KEY,
            title TEXT,
            deleted_at TEXT
        )
    """)
    
    deleted_count = 0
    for image_id, title in no_tag_images:
        try:
            # è®°å½•åˆ°åˆ é™¤è¡¨
            cursor.execute("""
                INSERT INTO deleted_images (id, title, deleted_at)
                VALUES (?, ?, ?)
            """, (image_id, title, datetime.now().isoformat()))
            
            # ä»ä¸»è¡¨åˆ é™¤
            cursor.execute("DELETE FROM images WHERE id = ?", (image_id,))
            deleted_count += 1
            
        except Exception as e:
            logger.error(f"åˆ é™¤å¤±è´¥ {image_id}: {e}")
    
    conn.commit()
    conn.close()
    
    logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤ {deleted_count} å¼ æ— æ ‡ç­¾å›¾ç‰‡")
    return deleted_count

def generate_summary_report():
    """ç”Ÿæˆæ›´æ–°æŠ¥å‘Š"""
    conn = sqlite3.connect('thinkora.db')
    cursor = conn.cursor()
    
    # è·å–æ›´æ–°åçš„ç»Ÿè®¡
    cursor.execute("""
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN tags = '[]' THEN 1 ELSE 0 END) as no_tags,
            SUM(CASE WHEN tags != '[]' THEN 1 ELSE 0 END) as with_tags,
            AVG(CASE 
                WHEN tags != '[]' 
                THEN json_array_length(tags) 
                ELSE 0 
            END) as avg_tags
        FROM images
    """)
    
    total, no_tags, with_tags, avg_tags = cursor.fetchone()
    
    # è·å–æ ‡ç­¾åˆ†å¸ƒ
    cursor.execute("""
        SELECT tags FROM images WHERE tags != '[]' LIMIT 100
    """)
    
    all_tags = []
    for row in cursor.fetchall():
        tags = json.loads(row[0])
        all_tags.extend(tags)
    
    # ç»Ÿè®¡æœ€å¸¸è§çš„æ ‡ç­¾
    tag_count = {}
    for tag in all_tags:
        tag_count[tag] = tag_count.get(tag, 0) + 1
    
    top_tags = sorted(tag_count.items(), key=lambda x: x[1], reverse=True)[:20]
    
    conn.close()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'statistics': {
            'total_images': total,
            'images_with_tags': with_tags,
            'images_without_tags': no_tags,
            'average_tags_per_image': round(avg_tags or 0, 2)
        },
        'top_20_tags': [{'tag': tag, 'count': count} for tag, count in top_tags],
        'tag_coverage': f"{(with_tags/total*100):.1f}%" if total > 0 else "0%"
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = f'logs/db_update_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æ‘˜è¦
    logger.info("\nğŸ“Š æ›´æ–°åçš„æ•°æ®åº“æ‘˜è¦:")
    logger.info(f"  æ€»å›¾ç‰‡æ•°: {total}")
    logger.info(f"  æœ‰æ ‡ç­¾å›¾ç‰‡: {with_tags} ({report['tag_coverage']})")
    logger.info(f"  å¹³å‡æ ‡ç­¾æ•°: {report['statistics']['average_tags_per_image']}")
    logger.info(f"\nğŸ·ï¸ Top 10 æ ‡ç­¾:")
    for tag, count in top_tags[:10]:
        logger.info(f"  - {tag}: {count}")
    
    return report

def main(auto_delete=False):
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ¸…ç†å’Œæ›´æ–°æ•°æ®åº“")
    
    # 1. åˆ†æå½“å‰æ•°æ®
    no_tag_images, total, no_tags, with_tags = analyze_current_data()
    
    if no_tags == 0:
        logger.info("âœ… æ•°æ®åº“ä¸­æ²¡æœ‰æ— æ ‡ç­¾çš„å›¾ç‰‡ï¼Œæ— éœ€æ¸…ç†")
        return
    
    # 2. å¤‡ä»½æ•°æ®åº“
    backup_database()
    
    # 3. å¯¼å…¥æ–°çš„å¸¦æ ‡ç­¾å›¾ç‰‡
    logger.info("\nğŸ“¥ å¯¼å…¥æ–°çš„å¸¦æ ‡ç­¾å›¾ç‰‡...")
    imported = import_new_images_to_db()
    
    # 4. è¯¢é—®æ˜¯å¦åˆ é™¤æ— æ ‡ç­¾å›¾ç‰‡
    if no_tags > 0:
        logger.info(f"\nâš ï¸ å‘ç° {no_tags} å¼ æ— æ ‡ç­¾å›¾ç‰‡")
        
        if auto_delete:
            logger.info("è‡ªåŠ¨æ¨¡å¼ï¼šåˆ é™¤æ— æ ‡ç­¾å›¾ç‰‡")
            remove_no_tag_images(no_tag_images)
        else:
            try:
                response = input("æ˜¯å¦åˆ é™¤è¿™äº›æ— æ ‡ç­¾å›¾ç‰‡? (y/n): ")
                if response.lower() == 'y':
                    remove_no_tag_images(no_tag_images)
                else:
                    logger.info("è·³è¿‡åˆ é™¤æ­¥éª¤")
            except EOFError:
                logger.info("éäº¤äº’æ¨¡å¼ï¼šè·³è¿‡åˆ é™¤æ­¥éª¤")
    
    # 5. ç”ŸæˆæŠ¥å‘Š
    logger.info("\nğŸ“Š ç”Ÿæˆæ›´æ–°æŠ¥å‘Š...")
    generate_summary_report()
    
    logger.info("\nâœ… æ•°æ®åº“æ›´æ–°å®Œæˆ!")

if __name__ == '__main__':
    import sys
    # å¦‚æœä¼ å…¥ --auto å‚æ•°ï¼Œè‡ªåŠ¨åˆ é™¤æ— æ ‡ç­¾å›¾ç‰‡
    auto_delete = '--auto' in sys.argv
    main(auto_delete)